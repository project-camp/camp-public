{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(999)\n",
    "options(scipen = 9)\n",
    "options(warn = -1) \n",
    "source(\"./environment/libraries.R\")\n",
    "knitr::opts_chunk$set(fig.height = 12, fig.width = 9, fig.dpi = 300)\n",
    "knitr::opts_chunk$set(warning = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "name <- \"Kenya_E1\"\n",
    "data_path <- \"./data\" # Define where input data are stored\n",
    "processed_data_path <- \"./test\"\n",
    "\n",
    "filepath <- file.path(data_path, paste0(name, \"_XRF_Results.xlsx\"))\n",
    "samples_geojson_path <- file.path(data_path, paste0(name, \"_samples.geojson\"))\n",
    "structures_geojson_path <- file.path(data_path, paste0(name, \"_topo_lines.geojson\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "source(\"./utils/functions/match_points_with_serials.R\")\n",
    "source(\"./utils/functions/create_quick_map.R\")\n",
    "source(\"./utils/functions/create_html_map.R\")\n",
    "\n",
    "raw_dataset <- match_points_with_serials(filepath, samples_geojson_path)\n",
    "dataset <- raw_dataset %>%\n",
    "  dplyr::filter(!is.na(Longitude.y),    \n",
    "                !is.na(Latitude.y), \n",
    "                !is.na(Easting), \n",
    "                !is.na(Northing)) %>%\n",
    "  dplyr::rename(\n",
    "    Longitude = Longitude.y,    \n",
    "    Latitude = Latitude.y\n",
    "  ) %>%\n",
    "  dplyr::select(-c(Longitude.x, Latitude.x))\n",
    "\n",
    "dataset <- dataset %>%\n",
    "  dplyr::mutate(\n",
    "    Longitude = as.numeric(Longitude),\n",
    "    Latitude = as.numeric(Latitude),\n",
    "    Easting = as.numeric(Easting),\n",
    "    Northing = as.numeric(Northing),\n",
    "    Elevation = as.numeric(Elevation)  \n",
    "  )\n",
    "\n",
    "dataset <- dataset %>% \n",
    "dplyr::select(\"Serial\", \"Type\", # Includes Serial and Type columns\n",
    "              \"Longitude\", \"Latitude\", \"Easting\", \"Northing\", \"Elevation\", # Spatial information\n",
    "              \"MgO\":\"U Err\") # Elemental information\n",
    "\n",
    "# Filter \"External (Outside)\" samples if necessary\n",
    "#dataset <- dataset %>% dplyr::filter(Type != \"External (Outside)\")\n",
    "\n",
    "head(dataset)\n",
    "structures <- st_read(structures_geojson_path, quiet = TRUE)\n",
    "create_quick_map(dataset, structures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "elements_all <- setdiff(names(dataset)[grep(\"^[A-Z][a-z]?$|^[A-Z][a-z]?[0-9]*O[0-9]*$\", names(dataset))], c(\"X\", \"Y\"))\n",
    "\n",
    "selected_data <- dataset %>% \n",
    "  dplyr::select(dplyr::any_of(elements_all)) %>%\n",
    "  dplyr::mutate(dplyr::across(dplyr::everything(), as.numeric)) %>%\n",
    "  dplyr::mutate(dplyr::across(dplyr::everything(), ~replace(., is.na(.), 0)))\n",
    "\n",
    "data_long <- selected_data %>%\n",
    "  tidyr::pivot_longer(dplyr::everything(), \n",
    "                     names_to = \"Element\", \n",
    "                     values_to = \"Value\")\n",
    "\n",
    "ggplot(data_long, aes(x = Element, y = Value)) +\n",
    "  geom_violin(fill = \"lightblue\", alpha = 0.5) +\n",
    "  geom_boxplot(width = 0.2, fill = \"white\", alpha = 0.5) +\n",
    "  theme_bw() +\n",
    "  coord_flip() +\n",
    "  labs(title = \"Combined Violin and Box Plot of Element Concentrations\",\n",
    "       x = \"Element\",\n",
    "       y = \"Concentration\") +\n",
    "  scale_y_log10() \n",
    "\n",
    "ggplot(data_long, aes(x = Value)) +\n",
    "  geom_histogram(bins = 30, fill = \"steelblue\", color = \"black\") +\n",
    "  facet_wrap(~Element, scales = \"free\") +\n",
    "  theme_bw() +\n",
    "  labs(title = \"Histograms of Element Concentrations\",\n",
    "       x = \"Concentration\",\n",
    "       y = \"Count\")\n",
    "\n",
    "ggplot(data_long, aes(x = Value)) +\n",
    "  geom_density(fill = \"steelblue\", alpha = 0.5) +\n",
    "  facet_wrap(~Element, scales = \"free\") +\n",
    "  theme_bw() +\n",
    "  labs(title = \"Density Distribution of Element Concentrations\",\n",
    "       x = \"Concentration\",\n",
    "       y = \"Density\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "element <- \"S\"\n",
    "data_single_element <- data_long %>% dplyr::filter(Element == element) \n",
    "\n",
    "ggplot(data_single_element, aes(x = Element, y = Value)) +\n",
    "  geom_violin(fill = \"lightblue\", alpha = 0.5) +\n",
    "  geom_boxplot(width = 0.2, fill = \"white\", alpha = 0.5) +\n",
    "  theme_bw() +\n",
    "  coord_flip() +\n",
    "  labs(title = paste(\"Combined Violin and Box Plot of\", \n",
    "                     data_single_element$Element[1], \n",
    "                     \"Concentration\"),\n",
    "       x = \"Element\",\n",
    "       y = \"Concentration\")\n",
    "\n",
    "ggplot(data_single_element, aes(x = Value)) +\n",
    "  geom_histogram(bins = 30, fill = \"steelblue\", color = \"black\") +\n",
    "  theme_bw() +\n",
    "  labs(title = paste(\"Combined Violin and Box Plot of\", \n",
    "                     data_single_element$Element[1], \n",
    "                     \"Concentration\"),\n",
    "       x = \"Concentration\",\n",
    "       y = \"Count\")\n",
    "\n",
    "ggplot(data_single_element, aes(x = Value)) +\n",
    "  geom_density(fill = \"steelblue\", alpha = 0.5) +\n",
    "  theme_bw() +\n",
    "  labs(title = paste(\"Combined Violin and Box Plot of\", \n",
    "                     data_single_element$Element[1], \n",
    "                     \"Concentration\"),\n",
    "       x = \"Concentration\",\n",
    "       y = \"Density\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "source(\"./utils/functions/below_lod_correction.R\")\n",
    "\n",
    "lod_values <- fromJSON(\"./utils/LOD_values.json\")\n",
    "# Substitute values below LOD with NA (both entries with \"<LOD\" and other values below LOD)\n",
    "dataset <- below_lod_correction(dataset, lod_values, method = \"oxide\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "source(\"./utils/functions/na_check.R\")\n",
    "source(\"./utils/functions/range_analysis_check.R\")\n",
    "source(\"./utils/functions/element_error_check.R\")\n",
    "\n",
    "cat(\"=== RUNNING NA CHECK ===\")\n",
    "head(na_check(dataset))\n",
    "\n",
    "cat(\"=== RUNNING RANGE ANALYSIS CHECK ===\")\n",
    "analysis_ranges <- fromJSON(\"./utils/analysis_ranges.json\")\n",
    "head(range_analysis_check(dataset, analysis_ranges, method = \"oxide\"))\n",
    "\n",
    "cat(\"=== RUNNING ELEMENT ERROR CHECK ===\")\n",
    "head(element_error_check(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "source(\"./utils/functions/na_filter.R\")\n",
    "source(\"./utils/functions/range_analysis_filter.R\")\n",
    "source(\"./utils/functions/element_error_filter.R\")\n",
    "\n",
    "# Remove columns with more than the desired threshold of missing values (in percentage)\n",
    "dataset <- na_filter(dataset, threshold = 100) \n",
    "\n",
    "# Remove columns with more than the desired threshold of outside analysis range (in percentage)\n",
    "dataset <- range_analysis_filter(dataset, analysis_ranges, method = \"oxide\", threshold = 20) \n",
    "\n",
    "# Remove columns with more than the desired threshold of below 3x error (in percentage)\n",
    "dataset <- element_error_filter(dataset, threshold = 20) \n",
    "\n",
    "# Remove elements that are not of interest (based on expert knowledge)\n",
    "elements_to_remove <- c()  # Define columns to remove (e.g., c(\"Y\", \"Zr\")) or leave empty\n",
    "dataset <- dataset %>%\n",
    "  dplyr::select(if (length(elements_to_remove) > 0) -all_of(elements_to_remove) \n",
    "                else everything())\n",
    "\n",
    "cat(\"=== RUNNING NA CHECK ===\")\n",
    "head(na_check(dataset))\n",
    "\n",
    "cat(\"=== RUNNING RANGE ANALYSIS CHECK ===\")\n",
    "head(range_analysis_check(dataset, analysis_ranges, method = \"oxide\"))\n",
    "\n",
    "cat(\"=== RUNNING ELEMENT ERROR CHECK ===\")\n",
    "head(element_error_check(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "elements_all <- setdiff(names(dataset)[grep(\"^[A-Z][a-z]?$|^[A-Z][a-z]?[0-9]*O[0-9]*$\", names(dataset))], c(\"X\", \"Y\"))\n",
    "selected_data <- dataset %>% \n",
    "  dplyr::select(dplyr::any_of(elements_all)) %>%\n",
    "  dplyr::mutate(dplyr::across(dplyr::everything(), as.numeric)) %>%\n",
    "  dplyr::mutate(dplyr::across(dplyr::everything(), ~replace(., is.na(.), 0)))\n",
    "data_long <- selected_data %>%\n",
    "  tidyr::pivot_longer(dplyr::everything(), \n",
    "                     names_to = \"Element\", \n",
    "                     values_to = \"Value\")\n",
    "\n",
    "ggplot(data_long, aes(x = Element, y = Value)) +\n",
    "  geom_violin(fill = \"lightblue\", alpha = 0.5) +\n",
    "  geom_boxplot(width = 0.2, fill = \"white\", alpha = 0.5) +\n",
    "  theme_bw() +\n",
    "  coord_flip() +\n",
    "  labs(title = \"Combined Violin and Box Plot of Element Concentrations\",\n",
    "       x = \"Element\",\n",
    "       y = \"Concentration\") +\n",
    "  scale_y_log10()  \n",
    "\n",
    "ggplot(data_long, aes(x = Value)) +\n",
    "  geom_histogram(bins = 30, fill = \"steelblue\", color = \"black\") +\n",
    "  facet_wrap(~Element, scales = \"free\") +\n",
    "  theme_bw() +\n",
    "  labs(title = \"Histograms of Element Concentrations\",\n",
    "       x = \"Concentration\",\n",
    "       y = \"Count\")\n",
    "\n",
    "ggplot(data_long, aes(x = Value)) +\n",
    "  geom_density(fill = \"steelblue\", alpha = 0.5) +\n",
    "  facet_wrap(~Element, scales = \"free\") +\n",
    "  theme_bw() +\n",
    "  labs(title = \"Density Distribution of Element Concentrations\",\n",
    "       x = \"Concentration\",\n",
    "       y = \"Density\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dataset_c <- dataset %>%\n",
    "  dplyr::select(-c(Serial, Type, Longitude, Latitude, Easting, Northing, Elevation)) %>% # Remove non-chemical data\n",
    "  dplyr::select(-matches(\" Err$\")) # Remove error columns)\n",
    "  \n",
    "par(bg = \"white\")\n",
    "if (any(is.na(dataset_c))) {\n",
    "  zCompositions::zPatterns(X = dataset_c, \n",
    "                          label = NA, \n",
    "                          bar.labels = TRUE)\n",
    "} else {\n",
    "  message(\"No missing values found in the dataset.\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(kableExtra)\n",
    "dataset_c_imputed <- data.frame(Serial = dataset$Serial, is_imputed = apply(dataset_c, 1, function(x) any(is.na(x))))\n",
    "dataset_c_isimputed <- cbind(dataset[1:6], # Add non-chemical columns (excluding Elevation)\n",
    "                             dataset_c, # Add compositional dataset\n",
    "                             \"is_imputed\" = dataset_c_imputed$is_imputed) # Add is_imputed column\n",
    "\n",
    "dataset_c_isimputed %>%\n",
    "  dplyr::filter(is_imputed == TRUE) %>%\n",
    "  dplyr::select(-c(Longitude, Latitude, Easting, Northing, is_imputed)) %>%\n",
    "  dplyr::relocate(Type, .after = last_col())  %>%\n",
    "  kable(format = \"html\") %>%\n",
    "  kableExtra::kable_styling(full_width = FALSE) %>% \n",
    "  kableExtra::scroll_box(width = \"100%\", height = \"400px\")\n",
    "\n",
    "create_quick_map(dataset_c_isimputed, structures, group_data = \"is_imputed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create data frame with LOD values (oxide method)\n",
    "lod_values <- data.frame(t(unlist(fromJSON(\"./utils/LOD_values.json\")$oxide_method))) # Load LOD values from JSON file into a data frame\n",
    "lod_values$SiO2 <- 0.01 # Set SiO2 LOD to 0.01 to avoid issues.\n",
    "lod_dataset_c <- lod_values[, intersect(colnames(lod_values), colnames(dataset_c))] / 10000 # Select relevant LODs and divide by 10000\n",
    "\n",
    "if (any(is.na(dataset_c))) {\n",
    "  message(\"Missing values found in the dataset. Pre-processing with multRepl for highly missing columns...\")\n",
    "\n",
    "  na_proportion <- colSums(is.na(dataset_c)) / nrow(dataset_c)\n",
    "  cols_to_multrepl <- names(na_proportion[na_proportion > 0.8]) # Identify columns with >80% NA\n",
    "\n",
    "  if (length(cols_to_multrepl) > 0) {\n",
    "    message(paste(\"Applying multRepl to columns with >80% NA:\", paste(cols_to_multrepl, collapse = \", \")))\n",
    "    dataset_c_preprocessed <- cbind(dataset_c, \"Res\" = 100 - rowSums(dataset_c, na.rm = TRUE)) \n",
    "    for (col_name in cols_to_multrepl) {\n",
    "      dataset_c_preprocessed[, col_name][is.na(dataset_c_preprocessed[, col_name])] <- 0.65 * lod_dataset_c[, col_name]\n",
    "    }\n",
    "    \n",
    "    for (i in 1:nrow(dataset_c_preprocessed)) { # Normalize rows to sum to 100\n",
    "      row <- dataset_c_preprocessed[i, ]\n",
    "      row_sum <- sum(row, na.rm = TRUE)\n",
    "      if (row_sum > 0) {\n",
    "        dataset_c_preprocessed[i, ] <- row * (100 / row_sum)\n",
    "      } else {\n",
    "        warning(paste(\"Row\", i, \"has sum 0 after replacement. Skipping normalization.\"))\n",
    "      }\n",
    "    }\n",
    "    \n",
    "    dataset_c <- dataset_c_preprocessed[, colnames(dataset_c), drop = FALSE]\n",
    "  } else {\n",
    "    message(\"No columns found with >80% NA. Skipping multRepl.\")\n",
    "  }\n",
    "\n",
    "  # Second NA check before calling lrEM\n",
    "  if (any(is.na(dataset_c))) {\n",
    "    message(\"Remaining missing values found. Proceeding with lrEM...\")\n",
    "    dataset_c <- zCompositions::lrEM(dataset_c,\n",
    "                                     label = NA,\n",
    "                                     dl = lod_dataset_c, \n",
    "                                     rob = TRUE) \n",
    "  } else {\n",
    "    message(\"No remaining missing values. Skipping lrEM.\")\n",
    "  }\n",
    "\n",
    "} else {\n",
    "  message(\"No missing values found in the dataset. Skipping multRepl and lrEM.\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "source(\"./utils/functions/oxide_to_element_transformation.R\")\n",
    "oxide_factors <- fromJSON(\"./utils/oxide_factors.json\") # Open .json file containing oxide to element factors\n",
    "dataset_c <- oxide_to_element_transformation(dataset_c, oxide_factors, convert_errors = FALSE)\n",
    "str(dataset_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "source(\"./utils/functions/mahalanobis_outliers.R\")\n",
    "# Perform Mahalanobis distance-based outlier detection\n",
    "dataset_c_outliers <- mahalanobis_outliers(ilr(dataset_c, v = ilrBase(dataset_c, method = \"balanced\")), # ilr transformation with choice of ilr base\n",
    "                                              alpha = 0.975, # Significance level for outlier detection\n",
    "                                              plot = TRUE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataset with logical column \"is_outlier\"\n",
    "dataset_c_isoutlier <- cbind(dataset[1:6], # Add non-chemical columns (excluding Elevation)\n",
    "                            \"Imputed\" = dataset_c_imputed$is_imputed, \n",
    "                             dataset_c,\n",
    "                             \"is_outlier\" = dataset_c_outliers$is_outlier) \n",
    "\n",
    "dataset_c_isoutlier %>%\n",
    "  dplyr::filter(is_outlier == TRUE) %>%\n",
    "  dplyr::select(-c(Longitude, Latitude, Easting, Northing, is_outlier)) %>%\n",
    "  dplyr::relocate(Type, .after = last_col()) %>%\n",
    "  kable(format = \"html\") %>%\n",
    "  kable_styling(full_width = FALSE) %>%\n",
    "  scroll_box(width = \"100%\", height = \"400px\")\n",
    "\n",
    "create_quick_map(dataset_c_isoutlier, structures, group_data = \"is_outlier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create final dataset including Serial, Type, spatial information and composition\n",
    "dataset_final <- dplyr::bind_cols(\n",
    "    dataset %>% dplyr::select(Serial, Type, Longitude, Latitude, Easting, Northing),\n",
    "    dataset_c)\n",
    "\n",
    "# Remove selected outliers from the final dataset, if any:\n",
    "outliers_to_remove <- c() # Include outliers to remove\n",
    "dataset <- dataset %>% \n",
    "    dplyr::filter(!Serial %in% outliers_to_remove)\n",
    "\n",
    "# Save the processed dataset\n",
    "write.csv(dataset_final, file.path(processed_data_path, paste0(name, \"_processed.csv\")), row.names = FALSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
